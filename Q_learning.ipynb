{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOpFKKso9DyNc9PLDC5UcRw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RKDash7/QLB-IoT/blob/main/Q_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dT7XbaCsQdz3"
      },
      "outputs": [],
      "source": [
        "#%%writefile mypackage/Iot_Edge.py\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "import simpy\n",
        "import random\n",
        "import numpy as np\n",
        "from Crypto.PublicKey import RSA\n",
        "from Crypto.Cipher import PKCS1_OAEP\n",
        "import hashlib\n",
        "from mypackage.Block_chain import generate_keys,encrypt_message,Blockchain,sign_transaction, generate_key\n",
        "\n",
        "initial_Energy=0\n",
        "Energ_consumption_per_iteration=[]\n",
        "dead_per_iteration=[]\n",
        "inital_dead_node=0\n",
        "e_T=\n",
        "#Q=0\n",
        "_, public_key = generate_key()\n",
        "# Step 1: Create the Multi-hop IoT Network with Edge Computing Nodes using NetworkX\n",
        "def create_multi_hop_iot_edge_network(num_devices=10, num_edge_nodes=2, connection_prob=0.3):\n",
        "    G = nx.erdos_renyi_graph(num_devices + num_edge_nodes, connection_prob)  # Random graph of devices + edge nodes\n",
        "    inital_energy=100*num_devices\n",
        "    for i in range(num_devices):\n",
        "        G.nodes[i]['device_type'] = 'sensor'  # IoT devices are sensors\n",
        "        G.nodes[i]['data'] = {'temperature': random.uniform(20, 30), 'humidity': random.uniform(30, 60)}\n",
        "        G.nodes[i]['energy'] = 100.0  # Initial energy of each sensor (arbitrary units)\n",
        "    for i in range(num_devices, num_devices + num_edge_nodes):\n",
        "        G.nodes[i]['device_type'] = 'edge_node'  # Edge computing nodes (gateways or local servers)\n",
        "        G.nodes[i]['processed_data'] = {}  # Store processed data from sensors\n",
        "        G.nodes[i]['energy'] = 1000.0  # Edge node energy\n",
        "    return G\n",
        "\n",
        "# Step 2: Visualize the IoT Edge Network\n",
        "def visualize_network(G):\n",
        "    pos = nx.spring_layout(G, seed=42)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    nx.draw(G, pos, with_labels=True, node_size=2000, node_color='lightblue', font_size=10, font_weight='bold', edge_color='gray')\n",
        "\n",
        "    # Add device type labels\n",
        "    for i in range(len(G.nodes)):\n",
        "        device_type = G.nodes[i]['device_type']\n",
        "        if device_type == 'sensor':\n",
        "            plt.text(pos[i][0], pos[i][1] + 0.05, device_type, fontsize=12, ha='center')\n",
        "        elif device_type == 'edge_node':\n",
        "            plt.text(pos[i][0], pos[i][1] + 0.05, device_type, fontsize=12, ha='center',color='red')\n",
        "\n",
        "    plt.title(\"Multi-hop IoT based Edge Computing Network Simulation with Q-Learning for Energy Minimization\")\n",
        "    plt.show()\n",
        "\n",
        "# Step 3: Q-learning Agent for IoT Device Routing\n",
        "class QLearningAgent:\n",
        "    def __init__(self, state_space, action_space, learning_rate=0.1, discount_factor=0.9, exploration_rate=1, exploration_decay=0.995):\n",
        "        self.state_space = state_space  # State space\n",
        "        self.action_space = action_space  # Action space\n",
        "        self.learning_rate = learning_rate  # Learning rate\n",
        "        self.discount_factor = discount_factor  # Discount factor\n",
        "        self.exploration_rate = exploration_rate  # Exploration rate (epsilon)\n",
        "        self.exploration_decay = exploration_decay  # Exploration decay rate\n",
        "        self.q_table = np.zeros((state_space, action_space))  # Q-table initialized to zero\n",
        "\n",
        "    def choose_action(self, state,communication_network,edge_nodes):\n",
        "        \"\"\"Epsilon-greedy action selection.\"\"\"\n",
        "        if random.uniform(0, 1) < self.exploration_rate:\n",
        "            neighbors =list(communication_network.neighbors(state)) # [i for i in range(self.state_space) if i != state and communication_network.nodes[i]['energy'] > 0]\n",
        "            if neighbors:\n",
        "              for i in range(len(neighbors)):\n",
        "                if neighbors[i]  in edge_nodes:\n",
        "                  return i\n",
        "                else:\n",
        "                  neigh=np.random.choice(range(0,len(neighbors)))\n",
        "                  if communication_network.nodes[neighbors[neigh]]['energy']>0:\n",
        "                    return neigh\n",
        "                  else:\n",
        "                    return None#np.random.choice(range(0,len(neighbors)))\n",
        "            else:\n",
        "                  return None#np.random.choice(range(0,self.action_space))\n",
        "            #return np.random.choice(range(0,len(neighbors)))\n",
        "        else:\n",
        "            # Exploit: choose the best action based on the Q-table\n",
        "            valid_actions = [i for i in range(self.action_space) if i < len(list(communication_network.neighbors(state)))]\n",
        "            if valid_actions:\n",
        "                return np.argmax(self.q_table[state])\n",
        "            else:\n",
        "              return None#np.random.choice(range(0,len(neighbors)))\n",
        "            #return np.argmax(self.q_table[state])\n",
        "\n",
        "\n",
        "    def learn(self, state, action, reward, next_state,communication_network):\n",
        "        \"\"\"Update the Q-table based on the agent's experience.\"\"\"\n",
        "\n",
        "        best_next_action = np.argmax(self.q_table[state])#np.argmax(self.q_table[next_state])\n",
        "        if communication_network.nodes[state]['energy']>0:\n",
        "          q_value = self.q_table[state, action]\n",
        "          if self.q_table[state, action]!=-np.inf:\n",
        "            self.q_table[state, action] = q_value + self.learning_rate * (reward + self.discount_factor * self.q_table[next_state, best_next_action] - q_value)\n",
        "\n",
        "        # Decay exploration rate\n",
        "        self.exploration_rate *= self.exploration_decay\n",
        "    def distance(self, node1, node2, communication_network):\n",
        "        #\"\"\"Calculate the Euclidean distance between two nodes.\"\"\"\n",
        "        d=np.linalg.norm(np.array(list(communication_network.nodes[node1]['pos'])) - np.array(list(communication_network.nodes[node2]['pos'])))\n",
        "        print(\"distance=\",d)\n",
        "        return d# np.linalg.norm(np.array(list(communication_network.nodes[node1]['pos'])) - np.array(list(communication_network.nodes[node2]['pos'])))\n",
        "    def reward_function(self, current_node, next_node, communication_network):\n",
        "        #\"\"\"Calculate the reward for a particular transition.\"\"\"\n",
        "        if communication_network.nodes[next_node]['energy'] <= 0:  # Avoid dead nodes\n",
        "            return -np.inf\n",
        "        dist = self.distance(current_node, next_node,communication_network)  # Call distance method of the class\n",
        "        if dist==0:\n",
        "          return 0\n",
        "        else:\n",
        "          return  1/dist #if communication_network.nodes[next_node]['energy']>0 else -np.inf\n",
        "    def visualize_q_table(self):\n",
        "      print(self.q_table)\n",
        "      plt.figure(figsize=(8, 8))\n",
        "      plt.imshow(self.q_table, cmap='hot', interpolation='nearest')\n",
        "      plt.colorbar()\n",
        "      plt.title(\"Q-Table (Routing Decisions)\")\n",
        "      plt.xlabel(\"Next Node\")\n",
        "      plt.ylabel(\"Current Node\")\n",
        "      plt.yticks(range(0,self.state_space,5))\n",
        "      plt.xticks(range(0,self.action_space,5))\n",
        "      plt.show()\n",
        "\n",
        "# Step 4: IoT Device Process with Q-learning Routing (Energy Consideration)\n",
        "def iot_device_with_q_learning(env,device_id, data, communication_network, edge_nodes, agent, node_state_space, energy_model):\n",
        "    \"\"\"\n",
        "    Simulate an IoT device (sensor) generating data and using Q-learning to send it to an edge node for processing.\n",
        "    Energy consumption is considered during the data transmission.\n",
        "    \"\"\"\n",
        "    global iniatl_energy,initial_dead_node\n",
        "\n",
        "\n",
        "    if communication_network.nodes[device_id]['energy'] > 0:\n",
        "      new_data = {'temperature': random.uniform(20, 30), 'humidity': random.uniform(30, 60)}\n",
        "      print(f\"Sensor {device_id} generating data: {new_data}\")\n",
        "      encrypted_data = encrypt_message(str(new_data), public_key)\n",
        "      communication_network.nodes[device_id]['data'] = encrypted_data\n",
        "      print(f\"Sensor {device_id} encrypting data: {encrypted_data}\")\n",
        "    source=device_id\n",
        "    path=[source]\n",
        "    while device_id not in edge_nodes:#not in edge_nodes:\n",
        "      if communication_network.nodes[device_id]['energy'] > 0:\n",
        "        #source=device_id\n",
        "        # Generate new sensor data\n",
        "\n",
        "        # Get the current state of the device (represented by the node it's connected to)\n",
        "\n",
        "        state = device_id  # Simple state: the node the device is connected to\n",
        "\n",
        "        neighbors = list(communication_network.neighbors(state))\n",
        "        # Choose an action using the Q-learning agent (choose next hop)\n",
        "        action = agent.choose_action(state,communication_network,edge_nodes)\n",
        "        if action==None:\n",
        "          break\n",
        "        print(action)\n",
        "        if neighbors[action] in edge_nodes:\n",
        "          neighbors = list(communication_network.neighbors(state))\n",
        "          next_hop = neighbors[action]\n",
        "          next_state = next_hop  # The next state is the next hop\n",
        "          reward = agent.reward_function(state, next_hop, communication_network)\n",
        "          agent.learn(state, action, reward, next_state,communication_network)\n",
        "\n",
        "          break\n",
        "        #print(action)\n",
        "        # The action corresponds to the next hop (an intermediate node or edge node)\n",
        "\n",
        "        num_valid_actions = len(neighbors)\n",
        "        #action = action % num_valid_actions\n",
        "        next_hop = neighbors[action]\n",
        "        print(f\"Sensor {device_id} forwarding data to Node {next_hop} via Q-learning\")\n",
        "\n",
        "        # Calculate energy consumption for transmission\n",
        "        energy_consumed = energy_model[state][next_hop]\n",
        "        if communication_network.nodes[state]['energy']>0 and communication_network.nodes[next_hop]['energy']>0:\n",
        "          communication_network.nodes[state]['energy'] -= energy_consumed  # Deduct energy from the current node\n",
        "          communication_network.nodes[next_hop]['energy'] -= e_R*n  # Deduct energy from the next node\n",
        "\n",
        "        else:\n",
        "          dead_node=dead_node+1\n",
        "          dead.append(dead_node)\n",
        "          break\n",
        "        E-=energy_consumed\n",
        "        initial_energy.append(E)\n",
        "        print(f\"Energy consumed: {energy_consumed} (Sensor {device_id} -> Node {next_hop})\")\n",
        "\n",
        "        # Simulate communication delay for multi-hop transmission\n",
        "        #yield env.timeout(random.randint(1, 3))  # Simulate delay\n",
        "\n",
        "        # If the next hop is an edge node, process the data\n",
        "        if next_hop in edge_nodes:\n",
        "            edge_node_data = communication_network.nodes[next_hop]['processed_data']\n",
        "            edge_node_data[device_id] = new_data  # Edge node processes the data\n",
        "            print(f\"Sensor {device_id} data processed at Edge Node {next_hop}\")\n",
        "\n",
        "        # Reward is inversely related to energy consumption, promoting energy-efficient routing\n",
        "        reward = agent.reward_function(state, next_hop, communication_network)  # Reward is negative energy consumption\n",
        "        if reward==np.nan:\n",
        "          reward=0\n",
        "        # Update the Q-learning agent with the new experience\n",
        "        next_state = next_hop  # The next state is the next hop\n",
        "        agent.learn(state, action, reward, next_state,communication_network)\n",
        "        path.append(next_state)\n",
        "        device_id=next_hop\n",
        "        # Wait before generating more data\n",
        "        yield env.timeout(random.randint(5, 10))\n",
        "      else:\n",
        "        break\n",
        "      Destination=np.random.choice(edge_nodes)\n",
        "      print(path)\n",
        "      print(f\"Sensor {source} data processed at Edge Node {Destination}\")\n",
        "# Step 5: Edge Node Process\n",
        "def edge_node(env, edge_node_id, communication_network):\n",
        "    \"\"\"\n",
        "    Simulate an Edge Node that processes data from IoT devices.\n",
        "    \"\"\"\n",
        "    while True:\n",
        "        # Collect and process data from connected devices (IoT sensors)\n",
        "        edge_node_data = communication_network.nodes[edge_node_id]['processed_data']\n",
        "\n",
        "        if edge_node_data:\n",
        "            print(f\"Edge Node {edge_node_id} processing data from devices: {edge_node_data}\")\n",
        "            communication_network.nodes[edge_node_id]['processed_data'] = {}  # Clear processed data\n",
        "        else:\n",
        "            print(f\"Edge Node {edge_node_id} waiting for data.\")\n",
        "\n",
        "        # Wait before checking for more data\n",
        "        yield env.timeout(random.randint(3, 7))\n",
        "def Energy_Consumption_plot(sim):\n",
        "  plt.plot(it,En)\n",
        "  plt.xlabel('Time')\n",
        "  plt.ylabel('Energy Consumption')\n",
        "  plt.title('Energy Consumption Over Time')\n",
        "  plt.yticks(range(1000,0 , -100))\n",
        "  plt.xticks(range(0,sim,10))\n",
        "  plt.grid(True)\n",
        "  plt.show()\n",
        "# Step 6: Simulate the Multi-hop IoT Network with Q-learning and Energy Minimization\n",
        "def Blockchain_connection(device_id1,device_id2,communication_network):\n",
        "    device1_private, device1_public, device1_private_pem, device1_public_pem = generate_keys()\n",
        "    device1 = {\"id\": device_id1, \"public_key\": device1_public}\n",
        "\n",
        "    # Device 2: Generate Keys\n",
        "    device2_private, device2_public, device2_private_pem, device2_public_pem = generate_keys()\n",
        "    device2 = {\"id\": device_id2, \"public_key\": device2_public}\n",
        "\n",
        "    # Create a Blockchain instance\n",
        "    blockchain = Blockchain()\n",
        "\n",
        "    # Device 1 creates a transaction to send to Device 2\n",
        "    message = f\"Sensor{device1['id']} sent to Edge Node{device2['id']} test packets\"\n",
        "    signature = sign_transaction(device1_private, message)\n",
        "\n",
        "    # Add the transaction to the blockchain (Device 1 sends funds to Device 2)\n",
        "    blockchain.add_transaction(device1, device2, 100, {'signature': signature, 'recipient': device2['id'], 'packets': 100},message)\n",
        "\n",
        "    # Device 1 mines a new block (Proof of Work)\n",
        "    last_proof = blockchain.last_block['proof']\n",
        "    proof = blockchain.proof_of_work(last_proof)\n",
        "\n",
        "    # Device 1 creates a new block after mining\n",
        "    previous_hash = blockchain.hash(blockchain.last_block)\n",
        "    blockchain.create_block(proof, previous_hash)\n",
        "\n",
        "    print(\"Blockchain after mining a new block:\")\n",
        "    for block in blockchain.chain:\n",
        "        print(block)\n",
        "def run_multi_hop_iot_edge_computing_q_learning_energy_simulation(num_devices=10, num_edge_nodes=2, connection_prob=0.3, simulation_time=100):\n",
        "    # Create the IoT network with edge nodes\n",
        "    global dead_node,E,Q\n",
        "    E=100*num_devices\n",
        "    G = create_multi_hop_iot_edge_network(num_devices, num_edge_nodes, connection_prob)\n",
        "\n",
        "    # List of edge nodes (their IDs)\n",
        "    edge_nodes = list(range(num_devices, num_devices + num_edge_nodes))\n",
        "\n",
        "    # Define state and action space for Q-learning\n",
        "    node_state_space = len(G.nodes)  # Each node can be considered a state\n",
        "    max_neighbors = max(len(list(G.neighbors(node))) for node in G.nodes)\n",
        "    action_space = max_neighbors# Number of neighbors each device has (possible actions)\n",
        "\n",
        "    pos = nx.spring_layout(G, seed=42)  # You can use other layout algorithms if needed\n",
        "    for node, position in pos.items():\n",
        "        G.nodes[node]['pos'] = position\n",
        "    # Energy consumption model (based on distance or hop count)\n",
        "    energy_model = {}\n",
        "    for node in G.nodes:\n",
        "        energy_model[node] = {}\n",
        "        for neighbor in G.neighbors(node):\n",
        "            distance = np.linalg.norm(np.array(list(G.nodes[node]['pos'])) - np.array(list(G.nodes[neighbor]['pos'])))\n",
        "            energy_model[node][neighbor] = alpha*(e_T*e_amp + e_amp*distance)  # Energy model: simple distance-based cost\n",
        "            #print(distance)\n",
        "    # Initialize Q-learning agent\n",
        "    agent = QLearningAgent(state_space=node_state_space, action_space=action_space)\n",
        "\n",
        "    # Set up the simulation environment\n",
        "    env = simpy.Environment()\n",
        "    for i in range(simulation_time):\n",
        "    # Start SimPy processes for each IoT device (sensor) and edge node\n",
        "      for device_id in range(num_devices):\n",
        "        Blockchain_connection(device_id,np.random.choice(edge_nodes),G)\n",
        "        if G.nodes[device_id]['energy'] <= 0 and dead_node!=num_devices:\n",
        "          dead_node=dead_node+1\n",
        "          continue\n",
        "        data = G.nodes[device_id]['data']\n",
        "        env.process(iot_device_with_q_learning(env, device_id, data, G, edge_nodes, agent, node_state_space, energy_model))\n",
        "        #iot_device_with_q_learning( device_id, data, G, edge_nodes, agent, node_state_space, energy_model)\n",
        "        #it.append(simulation_time)\n",
        "      #for edge_node_id in edge_nodes:\n",
        "        #env.process(edge_node(env, edge_node_id, G))\n",
        "        #edge_node( edge_node_id, G)\n",
        "    # Run the simulation\n",
        "\n",
        "    env.run(until=simulation_time)\n",
        "\n",
        "    # Visualize the network after the simulation\n",
        "    visualize_network(G)\n",
        "    agent.visualize_q_table()\n",
        "\n",
        "# Run the Multi-hop IoT Edge Computing simulation with Q-learning for energy minimization\n",
        "\n",
        "run_multi_hop_iot_edge_computing_q_learning_energy_simulation(num_devices=10, num_edge_nodes=2, connection_prob=0.3, simulation_time=1000)\n"
      ]
    }
  ]
}